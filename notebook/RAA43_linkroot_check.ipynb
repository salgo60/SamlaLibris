{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97ad0794-ab6b-4f49-b125-10d494bc131c",
   "metadata": {},
   "source": [
    "* [#43](https://github.com/salgo60/SamlaLibris/issues/43)\n",
    "\n",
    "* [RAA43_linkroot_check.ipynb](https://github.com/salgo60/SamlaLibris/blob/master/notebook/RAA43_linkroot_check.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57658046-1932-40e8-b479-f441464a263a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2025-12-06 16:04:49\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = now.timestamp()\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Start:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a38c20e-6e31-4bf3-91e7-4a99637907d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"./results/links_raa_2025_11_30.csv\" # 113 000 poster\n",
    "file=\"./results/links_raa_2025_12_01.csv\" # 305 000 poster \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "529d0253-9725-4ce4-a8c0-d5b3d9e0257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/salgo/Documents/GitHub/SamlaLibris/notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e795d96b-8227-4469-8ecd-8f7f9b6d5159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring 305250 external links (sample):   2%| | 5785/305250 [33:44<25:29:39,  IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Measuring 305250 external links (sample):  14%|▏| 41869/305250 [3:30:58<39:39:24"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "External Link Health Study – RAA (Sample / HTML)\n",
    "\n",
    "- Loads links_raa_2025_11_30.csv\n",
    "- Samples ~300 links for a pilot run\n",
    "- Measures link availability (HTTP HEAD)\n",
    "- Detects legacy DSpace XMLUI links\n",
    "- Generates an HTML report (STATUS_REPORT.html)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urlparse, quote\n",
    "from datetime import date\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Configuration\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "INPUT_CSV = file\n",
    "OUTPUT_DIR = \"./results\"\n",
    "\n",
    "USER_AGENT = \"Wikipedia link health research\"\n",
    "TIMEOUT = 10          # seconds\n",
    "#DELAY = 0.05          # politeness delay between requests\n",
    "DELAY = 0          # politeness delay between requests\n",
    "\n",
    "SAMPLE_SIZE = None     # set to None for full run\n",
    "RANDOM_STATE = 42     # reproducible sample\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Load data + sample\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "df_full = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "if SAMPLE_SIZE:\n",
    "    # sample per Wikipedia page to get some spread\n",
    "    df = (\n",
    "        df_full\n",
    "        .drop_duplicates(subset=[\"Wikipedia-sida\", \"Extern länk\"])\n",
    "        .groupby(\"Wikipedia-sida\", group_keys=False)\n",
    "        .apply(lambda x: x.sample(\n",
    "            min(max(1, SAMPLE_SIZE // max(1, len(df_full[\"Wikipedia-sida\"].unique()))), len(x)),\n",
    "            random_state=RANDOM_STATE\n",
    "        ))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # If we overshoot a bit, trim to exact SAMPLE_SIZE\n",
    "    if len(df) > SAMPLE_SIZE:\n",
    "        df = df.sample(n=SAMPLE_SIZE, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "else:\n",
    "    df = df_full\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Helpers\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def extract_wiki_lang(url):\n",
    "    try:\n",
    "        return url.split(\"//\")[1].split(\".\")[0]\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def extract_year(url):\n",
    "    if not isinstance(url, str):\n",
    "        return None\n",
    "    m = re.search(r\"(19\\d{2}|20\\d{2})\", url)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def is_legacy_dspace(url):\n",
    "    if not isinstance(url, str):\n",
    "        return False\n",
    "    return \"/xmlui/\" in url or \"/bitstream/handle/\" in url\n",
    "\n",
    "def raa_migration_hint(url):\n",
    "    if not isinstance(url, str):\n",
    "        return None\n",
    "    if \"samla.raa.se\" not in url:\n",
    "        return None\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    base = re.sub(r\"\\.pdf$\", \"\", filename, flags=re.I)\n",
    "    return f\"https://samla.raa.se/discover?query={quote(base)}\"\n",
    "\n",
    "def article_label(url):\n",
    "    \"\"\"Show a nicer label than the raw Wikipedia URL.\"\"\"\n",
    "    if not isinstance(url, str):\n",
    "        return \"\"\n",
    "    if \"/wiki/\" in url:\n",
    "        title = url.split(\"/wiki/\")[-1]\n",
    "        return title.replace(\"_\", \" \")\n",
    "    return url\n",
    "\n",
    "# measurement (network) ---------------------------------------------\n",
    "\n",
    "def check_url(url):\n",
    "    \"\"\"\n",
    "    Measure availability of a single URL.\n",
    "\n",
    "    Returns dict with:\n",
    "        status: HTTP status or None\n",
    "        error:  reason for failure (if any)\n",
    "        elapsed: response time in seconds\n",
    "    \"\"\"\n",
    "    try:\n",
    "        r = requests.head(\n",
    "            url,\n",
    "            allow_redirects=True,\n",
    "            timeout=TIMEOUT,\n",
    "            headers={\"User-Agent\": USER_AGENT}\n",
    "        )\n",
    "        time.sleep(DELAY)\n",
    "        return {\n",
    "            \"status\": r.status_code,\n",
    "            \"error\": None,\n",
    "            \"elapsed\": r.elapsed.total_seconds()\n",
    "        }\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        time.sleep(DELAY)\n",
    "        return {\"status\": None, \"error\": \"timeout\", \"elapsed\": None}\n",
    "\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        time.sleep(DELAY)\n",
    "        return {\"status\": None, \"error\": \"connection_error\", \"elapsed\": None}\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        time.sleep(DELAY)\n",
    "        return {\"status\": None, \"error\": type(e).__name__, \"elapsed\": None}\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Enrich dataframe\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "df[\"wiki\"] = df[\"Wikipedia-sida\"].apply(extract_wiki_lang)\n",
    "df[\"year\"] = df[\"Extern länk\"].apply(extract_year)\n",
    "df[\"legacy_dspace\"] = df[\"Extern länk\"].apply(is_legacy_dspace)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Measurement with progress bar\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "tqdm.pandas(desc=f\"Measuring {len(df)} external links (sample)\")\n",
    "\n",
    "results = df[\"Extern länk\"].progress_apply(check_url)\n",
    "\n",
    "df[\"status\"] = results.apply(lambda r: r[\"status\"])\n",
    "df[\"error\"] = results.apply(lambda r: r[\"error\"])\n",
    "df[\"elapsed\"] = results.apply(lambda r: r[\"elapsed\"])\n",
    "df[\"is_broken\"] = df[\"status\"].isin([404, None])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Manual repair candidates (legacy DSpace)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "manual_repair = df[\n",
    "    (df[\"is_broken\"]) &\n",
    "    (df[\"legacy_dspace\"])\n",
    "].copy()\n",
    "\n",
    "manual_repair[\"repair_reason\"] = \"RAA DSpace XMLUI migration\"\n",
    "manual_repair[\"migration_hint\"] = manual_repair[\"Extern länk\"].apply(raa_migration_hint)\n",
    "\n",
    "manual_repair.to_csv(\n",
    "    f\"{OUTPUT_DIR}/links_needing_manual_repair_sample.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Statistics\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "wiki_stats = (\n",
    "    df.groupby(\"wiki\")\n",
    "      .agg(\n",
    "          links_total=(\"Extern länk\", \"count\"),\n",
    "          broken_links=(\"is_broken\", \"sum\"),\n",
    "          legacy_dspace=(\"legacy_dspace\", \"sum\")\n",
    "      )\n",
    "      .sort_values(\"broken_links\", ascending=False)\n",
    ")\n",
    "\n",
    "wiki_stats[\"broken_pct\"] = (\n",
    "    wiki_stats[\"broken_links\"] / wiki_stats[\"links_total\"] * 100\n",
    ").round(2)\n",
    "\n",
    "lang_stats = (\n",
    "    df.groupby([\"lang_code\", \"lang_name\"])\n",
    "      .agg(\n",
    "          links=(\"Extern länk\", \"count\"),\n",
    "          broken=(\"is_broken\", \"sum\")\n",
    "      )\n",
    ")\n",
    "\n",
    "lang_stats[\"broken_pct\"] = (\n",
    "    lang_stats[\"broken\"] / lang_stats[\"links\"] * 100\n",
    ").round(2)\n",
    "\n",
    "year_stats = (\n",
    "    df.dropna(subset=[\"year\"])\n",
    "      .groupby(\"year\")\n",
    "      .agg(\n",
    "          links=(\"Extern länk\", \"count\"),\n",
    "          broken=(\"is_broken\", \"sum\"),\n",
    "          legacy=(\"legacy_dspace\", \"sum\")\n",
    "      )\n",
    ")\n",
    "\n",
    "year_stats[\"broken_pct\"] = (\n",
    "    year_stats[\"broken\"] / year_stats[\"links\"] * 100\n",
    ").round(2)\n",
    "\n",
    "domain_health = (\n",
    "    df.groupby(\"domain\")\n",
    "      .agg(\n",
    "          checks=(\"Extern länk\", \"count\"),\n",
    "          ok=(\"status\", lambda s: (s == 200).sum()),\n",
    "          timeouts=(\"error\", lambda e: (e == \"timeout\").sum()),\n",
    "          conn_errors=(\"error\", lambda e: (e == \"connection_error\").sum()),\n",
    "          mean_latency=(\"elapsed\", \"mean\")\n",
    "      )\n",
    ")\n",
    "\n",
    "domain_health[\"problem_ratio\"] = (\n",
    "    (domain_health[\"timeouts\"] + domain_health[\"conn_errors\"]) /\n",
    "    domain_health[\"checks\"]\n",
    ").round(2)\n",
    "\n",
    "domain_health.to_csv(f\"{OUTPUT_DIR}/domain_health_sample.csv\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# HTML report\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "today = date.today().isoformat()\n",
    "\n",
    "scope_note = (\n",
    "    f\"This is a <strong>pilot measurement</strong> based on \"\n",
    "    f\"{len(df)} sampled links from the full dataset.\"\n",
    "    if SAMPLE_SIZE else\n",
    "    \"This measurement covers the full dataset.\"\n",
    ")\n",
    "\n",
    "# prepare nice HTML versions of tables\n",
    "html_wiki_stats = wiki_stats.head(15).to_html(border=1, classes=\"table table-sm\", justify=\"left\")\n",
    "html_lang_stats = lang_stats.sort_values(\"broken\", ascending=False).head(15).to_html(border=1, classes=\"table table-sm\", justify=\"left\")\n",
    "html_year_stats = year_stats.tail(20).to_html(border=1, classes=\"table table-sm\", justify=\"left\")\n",
    "blocked = domain_health[\n",
    "    (domain_health[\"checks\"] >= 20) &\n",
    "    (domain_health[\"problem_ratio\"] > 0.9)\n",
    "].sort_values(\"problem_ratio\", ascending=False)\n",
    "html_blocked = blocked.to_html(border=1, classes=\"table table-sm\", justify=\"left\") if len(blocked) else \"<p>No clearly blocked domains in this sample.</p>\"\n",
    "\n",
    "# manual repair table – clickable Wikipedia + external links\n",
    "mr = manual_repair[\n",
    "    [\"Wikipedia-sida\", \"Extern länk\", \"repair_reason\", \"migration_hint\"]\n",
    "].head(25).copy()\n",
    "\n",
    "mr[\"Wikipedia-sida\"] = mr[\"Wikipedia-sida\"].apply(\n",
    "    lambda u: f'<a href=\"{u}\">{article_label(u)}</a>'\n",
    ")\n",
    "mr[\"Extern länk\"] = mr[\"Extern länk\"].apply(\n",
    "    lambda u: f'<a href=\"{u}\">{u}</a>'\n",
    ")\n",
    "mr[\"migration_hint\"] = mr[\"migration_hint\"].apply(\n",
    "    lambda u: f'<a href=\"{u}\">{u}</a>' if isinstance(u, str) else \"\"\n",
    ")\n",
    "\n",
    "html_manual_repair = mr.to_html(\n",
    "    escape=False,\n",
    "    border=1,\n",
    "    classes=\"table table-sm\",\n",
    "    index=False,\n",
    "    justify=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b8e626-de8d-4e43-bcd3-c07a3902fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "broken = df[df[\"is_broken\"]].copy()\n",
    "\n",
    "broken_display = broken[\n",
    "    [\"Wikipedia-sida\", \"Extern länk\", \"status\", \"error\"]\n",
    "].head(200)\n",
    "\n",
    "html_broken = broken_display.to_html(\n",
    "    escape=False,\n",
    "    border=1,\n",
    "    classes=\"table table-sm\",\n",
    "    index=False,\n",
    "    justify=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377f4c9-6db4-46ea-9919-d4f88c9bc1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3086482-734a-4dcf-aac5-0e48db004392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663e8c32-7083-4303-a645-9fda38e92342",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "html = f\"\"\"<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "<meta charset=\"utf-8\">\n",
    "<title>External Link Health Study – RAA (Sample)</title>\n",
    "<style>\n",
    "body {{\n",
    "    font-family: system-ui, -apple-system, BlinkMacSystemFont, \"Segoe UI\", sans-serif;\n",
    "    margin: 2rem;\n",
    "    line-height: 1.5;\n",
    "}}\n",
    "h1, h2, h3 {{\n",
    "    font-weight: 600;\n",
    "}}\n",
    ".table {{\n",
    "    border-collapse: collapse;\n",
    "    margin-top: 0.5rem;\n",
    "    margin-bottom: 1.5rem;\n",
    "    font-size: 0.9rem;\n",
    "}}\n",
    ".table th, .table td {{\n",
    "    border: 1px solid #ccc;\n",
    "    padding: 0.3rem 0.5rem;\n",
    "}}\n",
    ".table thead {{\n",
    "    background: #f2f2f2;\n",
    "}}\n",
    "code {{\n",
    "    background: #f5f5f5;\n",
    "    padding: 0.1rem 0.3rem;\n",
    "    border-radius: 3px;\n",
    "}}\n",
    "small {{\n",
    "    color: #666;\n",
    "}}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<h1>External Link Health Study – RAA (Sample)</h1>\n",
    "<p><strong>Last updated:</strong> {today}</p>\n",
    "<p>{scope_note}</p>\n",
    "\n",
    "<h2>Scope and method</h2>\n",
    "<p>\n",
    "This page reports HTTP availability of external links used in Wikipedia,\n",
    "with a focus on links to Riksantikvarieämbetet and related domains.\n",
    "It measures <em>technical accessibility</em> of URLs, not the quality of\n",
    "their content.\n",
    "</p>\n",
    "\n",
    "<h2>Summary</h2>\n",
    "<ul>\n",
    "  <li><strong>Total links measured:</strong> {len(df):,}</li>\n",
    "  <li><strong>Broken links:</strong> {df[\"is_broken\"].sum():,} ({df[\"is_broken\"].mean():.1%})</li>\n",
    "  <li><strong>Legacy DSpace (XMLUI) links:</strong> {df[\"legacy_dspace\"].sum():,}</li>\n",
    "</ul>\n",
    "\n",
    "<h2>Broken links by Wikipedia (Top 15)</h2>\n",
    "{html_wiki_stats}\n",
    "\n",
    "<h2>Broken links by content language (Top 15)</h2>\n",
    "{html_lang_stats}\n",
    "\n",
    "<h2>Link rot over time (year heuristic)</h2>\n",
    "{html_year_stats}\n",
    "\n",
    "<h2>Domains showing blocking or throttling (sample-based)</h2>\n",
    "{html_blocked}\n",
    "\n",
    "\n",
    "<p><small>\n",
    "Full sample CSV for this run:\n",
    "<code>results/links_needing_manual_repair_sample.csv</code><br>\n",
    "Domain diagnostics:\n",
    "<code>results/domain_health_sample.csv</code>\n",
    "</small></p>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "from datetime import date\n",
    "\n",
    "today_str = date.today().strftime(\"%Y_%m_%d\")\n",
    "output_filename = f\"STATUS_REPORT_{today_str}.html\"\n",
    "\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html)\n",
    "\n",
    "print(f\"✅ HTML report generated: {output_filename}\")\n",
    "print(\"✅ Sample CSVs written to ./results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91557838-1245-44cf-b1f7-c6252e96f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"failure_type\"] = None\n",
    "\n",
    "df.loc[df[\"error\"] == \"soft_404\", \"failure_type\"] = \"soft_404\"\n",
    "df.loc[df[\"status\"] == 404, \"failure_type\"] = \"hard_404\"\n",
    "df.loc[df[\"error\"] == \"timeout\", \"failure_type\"] = \"timeout\"\n",
    "df.loc[df[\"error\"] == \"connection_error\", \"failure_type\"] = \"connection_error\" \n",
    "\n",
    "MANUAL_FAILURES = {\"soft_404\", \"hard_404\"} \n",
    "all_failures = df[df[\"is_broken\"]].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af9472f-c92c-4f26-b785-23e2657960fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_failures.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d363c9e-cf89-4b08-aab2-b20601261366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c256eb0-8feb-4e3d-bec6-6730e30b7f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_failures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b44249d-4abf-41cc-853d-4244acfd5fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"wiki\"].value_counts().head())\n",
    "Series([], Name: count, dtype: int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c967ac-9813-41c1-bc56-4a3711ffaffa",
   "metadata": {},
   "outputs": [],
   "source": [
    " # End timer and calculate duration\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time# Bygg audit-lager för den här etappen\n",
    "\n",
    "# Print current date and total time\n",
    "print(\"Date:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "print(\"Total time elapsed: {:02.0f} minutes {:05.2f} seconds\".format(minutes, seconds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b47af84-29ba-4882-8874-949117bc8ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
